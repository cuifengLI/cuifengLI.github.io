<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="utf-8">
  
  <title>python网络爬虫与信息提取 | 莫春</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="python的安装​        python是一种面向对象、直译式计算机程序设计语言，也是一种功能强大而完善的通用型语言，这种语言具有非常简洁而清晰的语法特点，适合完成各种高层任务，几乎可以在所有的操作系统中运行。python3.6环境的安装： Requests库安装方法：​        Requests库：作为自动爬取HTML页面自动网络提交，是公认爬取网页最好的第三方库，具有简单简介的优">
<meta name="keywords" content="python,网络爬虫,信息提取">
<meta property="og:type" content="article">
<meta property="og:title" content="python网络爬虫与信息提取">
<meta property="og:url" content="http://yoursite.com/2019/08/26/python网络爬虫与信息提取/index.html">
<meta property="og:site_name" content="莫春">
<meta property="og:description" content="python的安装​        python是一种面向对象、直译式计算机程序设计语言，也是一种功能强大而完善的通用型语言，这种语言具有非常简洁而清晰的语法特点，适合完成各种高层任务，几乎可以在所有的操作系统中运行。python3.6环境的安装： Requests库安装方法：​        Requests库：作为自动爬取HTML页面自动网络提交，是公认爬取网页最好的第三方库，具有简单简介的优">
<meta property="og:locale" content="en">
<meta property="og:image" content="e:%5CGit%5Cboke%5Csource_posts%5CS90825-19275866.jpg">
<meta property="og:updated_time" content="2019-09-15T01:57:44.500Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="python网络爬虫与信息提取">
<meta name="twitter:description" content="python的安装​        python是一种面向对象、直译式计算机程序设计语言，也是一种功能强大而完善的通用型语言，这种语言具有非常简洁而清晰的语法特点，适合完成各种高层任务，几乎可以在所有的操作系统中运行。python3.6环境的安装： Requests库安装方法：​        Requests库：作为自动爬取HTML页面自动网络提交，是公认爬取网页最好的第三方库，具有简单简介的优">
<meta name="twitter:image" content="e:%5CGit%5Cboke%5Csource_posts%5CS90825-19275866.jpg">
  
  <link rel="stylesheet" href="//cdn.bootcss.com/highlight.js/9.2.0/styles/github.min.css">
  <script src="//cdn.bootcss.com/highlight.js/9.2.0/highlight.min.js"></script>
  <script>
    document.addEventListener('DOMContentLoaded', (event) => {
      document.querySelectorAll('pre code').forEach((block) => {
        hljs.highlightBlock(block);
      });
    });
  </script>
  <link rel="stylesheet" href="/css/index.css">
</head>
</html>
<body style="


  background-color: #eff0f6

">
  <div id="container">
    <nav id="nav">
  <header class="header">
    <a href="/" class="title">Clover Tuan</a>
  </header>
  <div class="ctnWrap">
    <div class="icons">
      
        
          
            <a href="https://dribbble.com/clovertuan" target="_blank" class="nav-icn iconfont icon-dribbble"></a>
          
        
          
            <a href="https://www.behance.net/clovertuan" target="_blank" class="nav-icn iconfont icon-behance"></a>
          
        
          
            <a href="http://clovertuan.lofter.com/" target="_blank" class="nav-icn iconfont icon-lofter"></a>
          
        
          
            <a href="https://www.instagram.com/clovertuan/" target="_blank" class="nav-icn iconfont icon-instagram"></a>
          
        
          
            <a href="https://github.com/cloverTuan" target="_blank" class="nav-icn iconfont icon-github"></a>
          
        
      
    </div>
    <div class="menu">
      
        
            <a href="/" class="nav-menu ">HOME</a>
          
        
            <a href="/archives" class="nav-menu ">ARCHIVE</a>
          
        
            <a href="/about" class="nav-menu ">ABOUT</a>
          
        
      
    </div>
  </div>
</nav>
    <div id="main"><section class="article">
  <h2 class="title">python网络爬虫与信息提取</h2>
  <p class="sub">Aug 26, 2019</p>
  <article class="content">
    <h3 id="python的安装"><a href="#python的安装" class="headerlink" title="python的安装"></a>python的安装</h3><p>​        python是一种面向对象、直译式计算机程序设计语言，也是一种功能强大而完善的通用型语言，这种语言具有非常简洁而清晰的语法特点，适合完成各种高层任务，几乎可以在所有的操作系统中运行。<a href="https://mp.weixin.qq.com/s/0RqtzljjjWjieDCmLdvLPg" target="_blank" rel="noopener">python3.6环境的安装</a>：</p>
<h3 id="Requests库安装方法："><a href="#Requests库安装方法：" class="headerlink" title="Requests库安装方法："></a>Requests库安装方法：</h3><p>​        Requests库：作为自动爬取HTML页面自动网络提交，是公认爬取网页最好的第三方库，具有简单简介的优质特点。<a href="http://cn.python-requests.org/zh_CN/latest/index.html" target="_blank" rel="noopener">Requests库官方文档中文版</a></p>
<ul>
<li>利用管理员权限启动cmd控制台</li>
<li>检验python环境是否已经安装并具有pip文件，否则会报错</li>
<li>使用如下代码检验pip是否已经安装，出现对应的版本证明安装成功</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip --version</span><br></pre></td></tr></table></figure>

<ul>
<li>上述所有条件都准备好的前提下，我们可以开始我们对Requests库的安装，使用如下代码：</li>
</ul>
<figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install requests</span><br></pre></td></tr></table></figure>

<h3 id="Requests库的get-方法"><a href="#Requests库的get-方法" class="headerlink" title="Requests库的get()方法"></a>Requests库的get()方法</h3><p>​        Requests库中的get()方法，通过借助“r”和“url（获取页面的url链接）”，构造一个向服务器请求资源的Requests对象，返回一个包含服务器资源的Response对象，response对象包含爬虫返回的全部内容</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">r=requests.get(url,params=<span class="literal">None</span>,**kwargs)</span><br><span class="line">&lt;!--常用方法如下：--&gt;</span><br><span class="line">r=requests.get(url)</span><br><span class="line">&lt;!--其中对上述参数解析：--&gt;</span><br><span class="line">&lt;!--url：获取页面的url链接--&gt;</span><br><span class="line">&lt;!--Response对象包含爬虫返回的全部信息内容--&gt;</span><br></pre></td></tr></table></figure>

<p>Response对象实例分析：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">r=requests.get(<span class="string">"http://www.baidu.com"</span>)</span><br><span class="line">print(r.status_code)  &lt;!--检测这个请求的状态码，如果返回值为200，则证明请求成功--&gt;</span><br><span class="line">type(r)  &lt;!--检测r的类型--&gt;</span><br><span class="line">r.headers  &lt;!--返回get页面请求的头部信息--&gt;</span><br></pre></td></tr></table></figure>

<p>​        Response对象的属性：</p>
<table>
<thead>
<tr>
<th align="center">Response对象</th>
<th align="center">属性</th>
<th align="center">备注</th>
</tr>
</thead>
<tbody><tr>
<td align="center">r.status_code</td>
<td align="center">表示HTTP请求的返回状态</td>
<td align="center">200表示连接成功，404表示失败</td>
</tr>
<tr>
<td align="center">r.text</td>
<td align="center">HTTP响应内容的字符串形式 ，即url对应的页面内容</td>
<td align="center"></td>
</tr>
<tr>
<td align="center">r.encoding</td>
<td align="center">从HTTP header中<strong><u>猜测</u></strong>的响应内容编码方式</td>
<td align="center">如果header中不存在 charset，则默认编码为ISO-8859-1</td>
</tr>
<tr>
<td align="center">r.apparent_encoding</td>
<td align="center">根据网页内容中<strong><u>分析</u></strong>出的响应内容编码方式</td>
<td align="center">备选编码方式</td>
</tr>
<tr>
<td align="center">r.content</td>
<td align="center">HTTP响应内容的二进制形式</td>
<td align="center"></td>
</tr>
</tbody></table>
<h3 id="爬取网页的通用代码框架"><a href="#爬取网页的通用代码框架" class="headerlink" title="爬取网页的通用代码框架"></a>爬取网页的通用代码框架</h3><p>​        Requests库并不适用于全部时候，出现网络异常等现象时会报错，所以正确理解Requests库的异常情况则很重要，下面列举出Requests库常见的异常：</p>
<table>
<thead>
<tr>
<th align="center">Requests库异常</th>
<th align="center">属性</th>
</tr>
</thead>
<tbody><tr>
<td align="center">requests.ConnectionError</td>
<td align="center">网络连接错误异常，如DNS查询失败，拒绝连接等</td>
</tr>
<tr>
<td align="center">requests.HTTPError</td>
<td align="center">HTTP协议方面错误异常</td>
</tr>
<tr>
<td align="center">requests.URLRequired</td>
<td align="center">URL缺失异常</td>
</tr>
<tr>
<td align="center">requests.TooManyRedirects</td>
<td align="center">超过大量定向次数，产生重定向异常</td>
</tr>
<tr>
<td align="center">requests.ConnectTimeout</td>
<td align="center">连接远程服务器超时异常</td>
</tr>
<tr>
<td align="center">requests.Timeout</td>
<td align="center">请求URL超时，产生超时异常</td>
</tr>
</tbody></table>
<p>常用爬取网页的通用代码框架：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt;<span class="keyword">import</span> requests</span><br><span class="line">&gt;&gt;&gt;<span class="function"><span class="keyword">def</span> <span class="title">getHTMLText</span><span class="params">(url)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        r=requests.get(url,timeout=<span class="number">30</span>)</span><br><span class="line">        r.rasise_for_status()<span class="comment">#返回状态码不是200，证明网络连接有问题，产生异常，所以except可以捕获到所用网络连接错误时的异常</span></span><br><span class="line">        r.encoding=r.apparent_encoding</span><br><span class="line">        <span class="keyword">return</span> r.text</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">"产生异常"</span></span><br><span class="line">    </span><br><span class="line"> <span class="comment">#以百度为例进行检测：   </span></span><br><span class="line"> &gt;&gt;&gt;url=<span class="string">"http://www.baidu.com"</span> </span><br><span class="line"> &gt;&gt;&gt;print(getHTMLText(url))</span><br></pre></td></tr></table></figure>

<h3 id="HTTP协议及Requests库方法"><a href="#HTTP协议及Requests库方法" class="headerlink" title="HTTP协议及Requests库方法"></a>HTTP协议及Requests库方法</h3><p>​        HTTP协议是一种基于“请求与响应”模式的、无状态的应用层协议，采用URL作为定位网络资源的标识。其中HTTP协议与Requests库相对应。关于HTTP协议规定如下：</p>
<p>​        HTTP URL理解：URL是通过HTTP协议存取资源的Internet路径，其中一个URL对应一个数据资源。URL格式：<a href="http://host[:port][path]" target="_blank" rel="noopener">http://host[:port][path]</a></p>
<ul>
<li>host：合法的Internet主机域名或IP地址</li>
<li>port：端口号，默认缺省端口为80</li>
<li>path：请求资源的内部路径</li>
</ul>
<table>
<thead>
<tr>
<th align="center">Requests库的方法</th>
<th align="center">HTTP协议方法</th>
<th align="center">说明</th>
<th align="center">功能一致性</th>
</tr>
</thead>
<tbody><tr>
<td align="center">equests.request()</td>
<td align="center"></td>
<td align="center">构造一个请求，支撑以下各方法的基础方法</td>
<td align="center"></td>
</tr>
<tr>
<td align="center">requests.get()</td>
<td align="center">GET</td>
<td align="center">获取HTML网页的主要方法</td>
<td align="center">一致</td>
</tr>
<tr>
<td align="center">requests.head()</td>
<td align="center">HEAD</td>
<td align="center">获取HTML网页头部信息的方法</td>
<td align="center">一致</td>
</tr>
<tr>
<td align="center">requests.post()</td>
<td align="center">POST</td>
<td align="center">向HTML网页提交POST请求</td>
<td align="center">一致</td>
</tr>
<tr>
<td align="center">requests.put()</td>
<td align="center">PUT</td>
<td align="center">向HTML网页提交PUT请求</td>
<td align="center">一致</td>
</tr>
<tr>
<td align="center">requests.patch()</td>
<td align="center">PATCH</td>
<td align="center">向HTML网页提交局部修改请求</td>
<td align="center">一致</td>
</tr>
<tr>
<td align="center">requests.delete()</td>
<td align="center">DELETE</td>
<td align="center">向HTML页面提交删除请求</td>
<td align="center">一致</td>
</tr>
</tbody></table>
<p>理解其中PATCH和PUT的区别：</p>
<p>​        假设 URL位置有一组用户数据，其中包括很多字段，例如有用户名、用户ID等需求：用户修改了用户名，其他保持不变，需要将改之后的内容部署到服务器端。</p>
<ol>
<li>采用PATCH：仅需要向URL提交用户名的局部更新请求，更好的节省网络带宽</li>
<li>采用PUT：必须将所有字段一并提交到URL，未提交字段被删除</li>
</ol>
<p><img src="E:%5CGit%5Cboke%5Csource_posts%5CS90825-19275866.jpg" alt="HTTP协议对资源的操作"></p>
<h3 id="Requests库主要方法及其解析"><a href="#Requests库主要方法及其解析" class="headerlink" title="Requests库主要方法及其解析"></a>Requests库主要方法及其解析</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">requests.request(method,url,**kwargs)</span><br><span class="line"><span class="comment">#其中**kwargs为控制访问的参数，均为可选项</span></span><br><span class="line"><span class="comment">#其中method对应七种不同的请求方法，示例如下，其他方法类似</span></span><br><span class="line">r=requests.request(<span class="string">'GET'</span>,url,**kwargs)</span><br><span class="line">r=requests.request(<span class="string">'HEAD'</span>,url,**kwargs)</span><br></pre></td></tr></table></figure>

<p>举例说明requests库的部分request方法：</p>
<ul>
<li><strong><u>控制参数为params：</u></strong>字典或字节序列，作为参数增加到uml中，对url起到修改的效果</li>
</ul>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">kv=&#123;<span class="string">'key1'</span>: <span class="string">'value1'</span>,<span class="string">'key2'</span>: <span class="string">'value2'</span>&#125;</span><br><span class="line">r=requests.request(<span class="string">'GET'</span>,<span class="string">'http://python123.io/ws'</span>,params=kv)</span><br><span class="line">print(r.url)</span><br><span class="line"></span><br><span class="line">//运行结果为：</span><br><span class="line">https://python123.io/ws?key1=value1&amp;key2=value2</span><br></pre></td></tr></table></figure>

<ul>
<li><strong><u>控制参数为data</u></strong>：重点作为向服务器提供或者提交资源时的文件</li>
<li><strong><u>控制参数为json：</u></strong>JSON格式的数据，作为Request的内容，将字典内容直接上传至服务器的json语上</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kv=&#123;<span class="string">'key1'</span>: <span class="string">'value1'</span>,<span class="string">'key2'</span>: <span class="string">'value2'</span>&#125;</span><br><span class="line">r=requests.request(<span class="string">'POST'</span>,<span class="string">'http://python123.io/ws'</span>,json=kv)</span><br></pre></td></tr></table></figure>

<ul>
<li><strong><u>控制参数为headers：</u></strong>可以通过这个字段定制访问url的http协议头</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hd=&#123;<span class="string">'user-agent'</span>:<span class="string">'Chrome/10'</span>&#125;</span><br><span class="line">r=requests.request(<span class="string">'POST'</span>,<span class="string">'http://python123.io/ws'</span>,headers=hd)</span><br></pre></td></tr></table></figure>

<p>‘headers’再向服务器访问链接时，服务器看到的’user-agent’字段将会是Chrome/10,指Chrome的第十版浏览器版本，所以我们可以通过这个字段模仿不同浏览器的不同版本</p>
<ul>
<li>控制参数为timeout：设定超时时间，以秒为单位,在设定的时间内没有产生我们访问的内容，将会产生一个timeout的异常</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">r=requests.request(<span class="string">'GET'</span>,<span class="string">'http://www.baidu.com'</span>,timeout=<span class="number">10</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>控制参数为proxies:设定访问代理服务器，可以增加登录认证,防止爬虫逆追踪的情况发生</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pxs=&#123;<span class="string">'http://user:pass@10.10.10.1:1234'</span> <span class="string">'https'</span>:<span class="string">'https://10.10.10.1:4321'</span>&#125;</span><br><span class="line">r=requests.request(<span class="string">'GET'</span>,<span class="string">'http://www.baidu.com'</span>,proxies=pxs)</span><br></pre></td></tr></table></figure>


  </article>
  <footer class="f-cf">
    
      <a href="/2019/09/20/python网络爬虫（2）/" class="link f-fl">⟵python网络爬虫（2）</a>
    
    
      <a href="/2019/07/13/利用hexo-github建立个人博客/" class="link f-fr">hexo+github建立个人博客⟶</a>
    
  </footer>
</section></div>
    <footer id="footer" class="f-cf">
  d.guangying@foxmail.com
  
    
      
        · <a href="https://dribbble.com/clovertuan" target="_blank" class="nav-icn">Dribbble</a>
      
    
      
        · <a href="https://www.behance.net/clovertuan" target="_blank" class="nav-icn">Behance</a>
      
    
      
        · <a href="http://clovertuan.lofter.com/" target="_blank" class="nav-icn">Lofter</a>
      
    
      
        · <a href="https://www.instagram.com/clovertuan/" target="_blank" class="nav-icn">Instagram</a>
      
    
      
        · <a href="https://github.com/cloverTuan" target="_blank" class="nav-icn">GitHub</a>
      
    
  
  <span class="copyright">All rights reserved @Clover Tuan</span>
</footer>
  </div>
</body>
</html>